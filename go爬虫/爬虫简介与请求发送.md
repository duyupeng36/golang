# 一 爬虫简介

- 什么是爬虫？
    - 就是通过编写程序**模拟**浏览器上网，
      然后让其去互联网上爬取数据的自动化程序
      
    - 简单来说就是一个HTTP客户端。

- 爬虫的分类：
    - 通用爬虫：
        - 抓取互联网中的一整张页面数据
    - 聚焦爬虫：
        - 抓取页面中的局部数据，流程如下
          - 明确URL (请求的地址，明确爬什么)
          - 发送请求，获取响应数据
          - 保存响应数据，提取有用信息
          - 处理数据（存储、使用）      

    - 增量式爬虫：
        - 用来**监测网站数据更新**的情况，以便爬取到网站最新更新出来的数据

- 反爬机制: 防止爬虫程序获取网站数据
    - 请求载体标识: `User-Agent`
    - ip访问频率限制
    - 数据加密
    - `robots`协议, 君子协议

- 反反爬策略: 破解反爬机制，获取被保护的数据

- 爬虫合法吗？
    - 爬取数据的行为**风险**的体现
        -  爬虫干扰了被访问网站的正常运营
        -  爬虫抓取了受到法律保护的特定类型的数据或信息。

    - 规避风险
        - **严格遵守**网站设置的`robots`协议
        - 在规避反爬虫措施的同时，需要优化自己的代码，
          **避免干扰被访问网站的正常运行**
        - 在使用、传播抓取到的信息时，应审查所抓取的内容，
          如发现属于用户的个人信息、隐私或者他人的商业秘密的，
          应及时停止并删除。

- `robots`协议：文本协议
    - 特性：防君子不防小人的文本协议


- 爬虫爬取哪些数据：
    - 资讯公司：特定领域的新闻数据的爬虫
    - 金融公司：关于各个公司的动态的信息，
    - 酒店/旅游：携程，去哪儿的酒店价格信息/机票，景点价格，其他旅游公司价格信息
    - 房地产、高铁：10大房地产楼盘门户网站，政府动态等
    - 强生保健医药：医疗数据，价格，目前的市场的行情
      对爬虫整体做了简单了解后，我们实现一个爬虫案例，尝试爬取百度贴吧中一些讯息。

# 二 请求发送
使用go语言发起网络请求初体验

**示例，发起get请求访问https://httpbin.org/get**
```go
package main

import (
	"fmt"
	"io"
	"net/http"
)

var url  = "https://httpbin.org/get"

func main() {
	// get
	response, err := http.Get(url)
	if err != nil {
		fmt.Println("请求失败")
		return
	}
	defer response.Body.Close()
	var buf []byte = make([]byte, 1024)
	var html string
	for {
		n, err := response.Body.Read(buf)
		if err != nil {
			if err == io.EOF {
				fmt.Println("读取完毕")
				break
			} else {
				fmt.Println("读取出错")
				return
			}
		}
		if n==0{
			fmt.Println("读取完毕")
			break
		}
		html += string(buf[:n])
	}
	fmt.Printf("爬虫爬取到的内容为: \n%s\n", html)
}
```
**运行程序得到的结果如下**
```json
{
  "args": {}, 
  "headers": {
    "Accept-Encoding": "gzip", 
    "Host": "httpbin.org", 
    "User-Agent": "Go-http-client/2.0", 
    "X-Amzn-Trace-Id": "Root=1-609d19f3-0852d4e835d4b4ff3aa14f8b"
  }, 
  "origin": "223.166.35.39", 
  "url": "https://httpbin.org/get"
}
```

**示例，爬取百度贴吧数据**
```go
package main

import (
	"fmt"
	"io/ioutil"
	"net/http"
	"strconv"
)


func HttpGet(url string) (html string) {
	response, err := http.Get(url)
	if err != nil {
		fmt.Println("请求发送错误")
		return
	}
	defer func() {
		err := response.Body.Close()
		fmt.Println("关闭主体出错，错误信息为: ", err)
	}()

	result, _ := ioutil.ReadAll(response.Body)
	html += string(result)
	return
}

func main() {
	for i := 0; i < 1; i++ {
		url := "https://tieba.baidu.com/f?kw=%E7%8E%8B%E8%80%85%E8%8D%A3%E8%80%80&ie=utf-8&cid=&tab=corearea&pn="+strconv.Itoa(i * 50)
		html := HttpGet(url)
		fmt.Printf("获取到内容|\n%s\n", html)
	}
}
```


## 2.1 通用发起请求的方法

帮我们实现所有`HTTP`请求的方法。主要涉及两个重要的类型，`Client` 和 `Request`。

`Client`即是发送 `HTTP` 请求的客户端，请求的执行都是由 `Client` 发起。
它提供了一些便利的请求方法，比如我们要发起一个`Get`请求，可通过 `client.Get(url)` 
实现。更通用的方式是通过 `client.Do(req)` 实现，`req` 属于 `Request` 类型。

接下来列举 `HTTP` 所有方法的实现代码。
* GET请求
    ```
    r, err := http.DefaultClient.Do(
        http.NewRequest(http.MethodGet, "https://api.github.com/events", nil))
    ```
* POST请求
    ```
    r, err := http.DefaultClient.Do(
        http.NewRequest(http.MethodPost, "http://httpbin.org/post", nil)
    ```
* PUT请求
    ```
    r, err := http.DefaultClient.Do(
        http.NewRequest(http.MethodPut, "http://httpbin.org/put", nil))
    ```
* DELETE请求
    ```
    r, err := http.DefaultClient.Do(
        http.NewRequest(http.MethodDelete, "http://httpbin.org/delete", nil))
    ```
* HEAD请求
    ```
    r, err := http.DefaultClient.Do(
        http.NewRequest(http.MethodHead, "http://httpbin.org/get", nil))
    ```
* OPTIONS请求
    ```
    r, err := http.DefaultClient.Do(
        http.NewRequest(http.MethodOptions, "http://httpbin.org/get", nil))
    ```

上面展示了`HTTP`所有方法的实现。这里还几点需要说明。
* `DefaultClient`，它是 `net/http` 包提供了默认客户端，
  一般的请求我们无需创建新的 `Client`，使用默认即可。

`GET`、`POST` 和 `HEAD` 的请求，`GO`提供了更便捷的实现方式，
`Request` 不用手动创建。
* GET请求
    ```
    r, err := http.DefaultClient.Get("http://httpbin.org/get")
    r, err := http.Get("http://httpbin.org/get")
    ```
* POST请求  
    ```
    bodyJson, _ := json.Marshal(map[string]interface{}{
        "key": "value",
    })
    r, err := http.DefaultClient.Post(
        "http://httpbin.org/post",
        "application/json",
        strings.NewReader(string(bodyJson)),
    )
    r, err := http.Post(
        "http://httpbin.org/post",
        "application/json",
        strings.NewReader(string(bodyJson)),
    )
    ```
  * `POST` 接口提交 `JSON` 数据的方式，主要 `content-type` 的设置，
    一般`JSON`接口的 `content-type` 为 `application/json`。
    
* HAND请求
    ```
    r, err := http.DefaultClient.Head("http://httpbin.org/get")
    r, err := http.Head("http://httpbin.org/get")
    ```
  


# 三 响应信息
执行请求成功，如何查看响应信息。要查看响应信息，可以大概了解下，响应通常哪些内容？
常见的有主体内容（`Body`）、状态信息（`Status`）、响应头部（`Header`）、
内容编码（`Encoding`）等。

## 3.1 Body主体
主体中保存的是url对应的网页内容。是一个`io.ReadCloser`接口对象。其操作类似与文件，
支持读取内容和关闭。

响应内容多样，如果是 `json`，可以直接使用 `json.Unmarshal` 进行解码。读取数据完毕后
要记得关闭。


## 3.2 Status和StatusCode
响应信息中，除了 Body 主体内容，还有其他信息，比如 status code 和 charset 等。

其中，`r.StatusCode` 是 `HTTP` 返回状态码码，
`Status` 是返回状态描述信息。

## 3.3 Header响应头
请求的响应头信息保存在该字段中，可以通过如下方式获取
```
r.Header.Get("content-type")
r.Header.Get("Content-Type")
```
`Key`: 不区分大小写

## 3.4 Encoding内容编码
对于响应内容，编码方式可能与程序解析不同，导致解析出的数据出现乱码情况。采用`http://golang.org/x/net/html/charset`
包来完成内容编码识别。使用`transform`包完成编码转换
```
func determineEncoding(r *bufio.Reader) encoding.Encoding {
	bytes, err := r.Peek(1024)
	if err != nil {
		fmt.Printf("err %v", err)
		return unicode.UTF8
	}
 
	e, _, _ := charset.DetermineEncoding(bytes, "")
 
	return e
}


bodyReader := bufio.NewReader(r.Body)
e := determineEncoding(bodyReader)
fmt.Printf("Encoding %v\n", e)
 
decodeReader := transform.NewReader(bodyReader, e.NewDecoder())
```
## 3.4 文件下载
如果访问内容是一张图片，我们如何把它下载下来呢? 如下程序所示
```
f, err := os.Create("as.jpg")
if err != nil {
panic(err)
}
defer func() { _ = f.Close() }()

_, err = io.Copy(f, r.Body)
if err != nil {
panic(err)
}
```
`r` 即 `Response`，利用 `os` 创建了新的文件，然后再通过 `io.Copy` 
将响应的内容保存进文件中。

# 四 请求定制
## 4.1 定制请求头
`Request` 已经提供了相应的方法，通过 `req.Header.Add` 即可完成请求头设置
```
req, err := http.NewRequest(http.MethodGet, "https://httpbin.org/get", nil)
if err != nil {
	panic(err)
}

req.Header.Add("user-agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0)")
```
## 4.2 url参数定制

通过将`键-值对`置于`URL`中，我们可以实现向特定地址传递数据。
该`键-值`将跟在一个问号的后面，例如`http://httpbin.org/get?key=val`。
手工构建 `URL` 会比较麻烦，我们可以通过 `net/http` 提供的方法来实现。

举个栗子，比如你想传递 `key1=value1` 和 `key2=value2` 到
`http://httpbin.org/get` 。代码如下：
```
req, err := http.NewRequest(http.MethodGet, "http://httpbin.org/get", nil)
if err != nil {
	panic(err)
}
 
params := make(url.Values)
params.Add("key1", "value1")
params.Add("key2", "value2")
 
req.URL.RawQuery = params.Encode()
 
// URL 的具体情况 http://httpbin.org/get?key1=value1&key2=value2
// fmt.Println(req.URL.String())
 
r, err := http.DefaultClient.Do(req)
```
`url.Values` 可以帮助组织 `QueryString`，查看源码发现 `url.Values`
其实是 `map[string][]string`类型。调用 `Encode` 方法，
将组织的字符串传递给请求 `req` 的 `RawQuery`

## 4.3 post请求参数定制
前面已经展示过了向 `POST` 接口提交 `JSON` 数据的方式。
接下来介绍下另外几种向 `POST` 接口提交数据的方式，即表单提交和文件提交。
### 4.3.1 表单数据提交
表单提交是一个很常用的功能，故而在 `net/http` 中，除了提供标准的用法外，
还给我们提供了简化的方法。

我们先来介绍个标准的实现方法。

举个例子，假设要向 `http://httpbin.org/post` 提交 `name` 为 `poloxue` 
和 `password` 为 `123456` 的表单。
```
payload := make(url.Values)
payload.Add("name", "poloxue")
payload.Add("password", "123456")
req, err := http.NewRequest(
	http.MethodPost,
	"https://httpbin.org/post",
	strings.NewReader(payload.Encode()),
)
if err != nil {
	panic(err)
}
req.Header.Add("Content-Type", "application/x-www-form-urlencoded")
 
r, err := http.DefaultClient.Do(req)
```
`POST` 的 `payload` 是形如 `name=poloxue&password=123456` 的字符串，
故而我们可以通过 `url.Values` 进行组织。

提交给 `NewRequest` 的内容必须是实现 `Reader` 接口的类型，
所以需要 `strings.NewReader`转化下。

`Form` 表单提交的 `content-type` 要是 `application/x-www-form-urlencoded`，
也要设置。

复杂的方式介绍完了。接着再介绍简化的方式，其实表单提交只需调用 `http.PostForm` 
即可完成。示例代码如下：
```
payload := make(url.Values)
payload.Add("name", "poloxue")
payload.Add("password", "123456")
r, err := http.PostForm("https://httpbin.org/post", form)
```

### 4.3.2 提交文件
举个例子，假设现在我有一个图片文件，名为 `as.jpg`，路径在 `/Users/polo` 目录下。
现在要将这个图片提交给 `http://httpbin.org/post`

我们要先组织 `POST` 提交的内容，代码如下：
```
filename := "/Users/polo/as.jpg"

f, err := os.Open(filename)
if err != nil {
    panic(err)
}
defer func () { _ = f.Close() }()

uploadBody := &bytes.Buffer{}
writer := multipart.NewWriter(uploadBody)

fWriter, err := writer.CreateFormFile("uploadFile", filename)
if err != nil {
    fmt.Printf("copy file writer %v", err)
}

_, err = io.Copy(fWriter, f)
if err != nil {
    panic(err)
}

fieldMap := map[string]string{
    "filename": filename,
}
for k, v := range fieldMap {
    _ = writer.WriteField(k, v)
}

err = writer.Close()
if err != nil {
    panic(err)
}
```
数据组织分为下面几步完成，如下：

* 第一步，打开将要上传的文件，使用 `defer f.Close()` 做好资源释放的准备；
* 第二步，创建存储上传内容的 `bytes.Buffer`，变量名为 `uploadBody`；
* 第三步，通过 `multipart.NewWriter` 创建 `writer`，用于向 `buffer`中写入文件提供的内容；
* 第四步，通过`writer.CreateFormFile` 创建上传文件并通过 `io.Copy` 向其中写入内容；
* 最后，通过 `writer.WriteField` 添加其他的附加信息，注意最后要把 `writer` 关闭；

至此，文件上传的数据就组织完成了。接下来，只需调用 `http.Post` 方法即可完成文件上传。
```
r, err := http.Post("https://httpbin.org/post", writer.FormDataContentType(), uploadBody)
```
有一点要注意，请求的`content-type`需要设置，而通过 `writer.FormDataContentType()` 
即能获得上传文件的类型。

## 4.4 设置Cookie
主要涉及两部分内容，即读取响应的 `cookie` 与设置请求的 `cookie`。
响应的 `cookie` 获取方式非常简单，直接调用 `r.Cookies` 即可。

重点来说说，如何设置请求`cookie`。`cookie`设置有两种方式，
一种设置在 `Client` 上，另一种是设置在 `Request` 上。

### 4.4.1 Client 上设置 Cookie
```
cookies := make([]*http.Cookie, 0)
 
cookies = append(cookies, &http.Cookie{
	Name:   "name",
	Value:  "poloxue",
	Domain: "httpbin.org",
	Path:   "/cookies",
})
cookies = append(cookies, &http.Cookie{
	Name:   "id",
	Value:  "10000",
	Domain: "httpbin.org",
	Path:   "/elsewhere",
})
 
url, err := url.Parse("https://httpbin.org/cookies")
if err != nil {
	panic(err)
}
 
jar, err := cookiejar.New(nil)
if err != nil {
	panic(err)
}
jar.SetCookies(url, cookies)
 
client := http.Client{Jar: jar}
 
r, err := client.Get("https://httpbin.org/cookies")
```
代码中，我们首先创建了 `http.Cookie` 切片，然后向其中添加了 `2` 个`Cookie` 数据。
这里通过 `cookiejar`，保存了 `2` 个新建的 `cookie`。

这次我们不能再使用默认的 `DefaultClient` 了，而是要创建新的 `Client`，
并将保存 `cookie` 信息的 `cookiejar` 与 `client` 绑定。
接下里，只需要使用新创建的 `Client` 发起请求即可

### 4.4.2 请求上设置 Cookie
请求上的 `cookie` 设置，通过 `req.AddCookie`即可实现

```
req, err := http.NewRequest(http.MethodGet, "http://httpbin.org/cookies", nil)
if err != nil {
	panic(err)
}
 
req.AddCookie(&http.Cookie{
	Name:   "name",
	Value:  "poloxue",
	Domain: "httpbin.org",
	Path:   "/cookies",
})
 
r, err := http.DefaultClient.Do(req)
```

`cookie` 设置 `Client` 和 设置在 `Request` 上有何区别？一个最易想到的区别就是，
**`Request`的`cookie`只是当次请求有效**，而 **`Client` 上的 `cookie` 是随时有效的**，
只要你用的是这个新创建的 `Client`。

## 4.4.3 重定向和请求历史
默认情况下，**所有类型请求都会自动处理重定向**。

`Python` 的 `requests` 包中 `HEAD` 请求是不重定向的，
但测试结果显示 `net/http` 的 `HEAD` 是自动重定向的。

`net/http` 中的重定向控制可以通过 `Client` 中的一个名为 `CheckRedirect` 
的成员控制，它是函数类型。定义如下
```
type Client struct {
	...
	CheckRedirect func(req *Request, via []*Request) error
	...
}
```
**循环重定向问题解决方式**
```
var r *http.Response
history := make([]*http.Response, 0)
 
client := http.Client{
	CheckRedirect: func(req *http.Request, hrs []*http.Request) error {
		if len(hrs) >= 10 {
			return errors.New("redirect to many times")
		}
 
		history = append(history, req.Response)
		return nil
	},
}
 
r, err := client.Get("https://github.com")
```

首先创建了 `http.Response` 切片的变量，名称为 `history`。
接着在 `http.Client` 中为 `CheckRedirect` 赋予一个匿名函数，
用于控制重定向的行为。`CheckRedirect` 函数的第一个参数表示下次将要请求的 
`Request`，第二个参数表示已经请求过的 `Request`。

当发生重定向时，当前的 `Request` 会保存上次请求的 `Response`，
故而此处可以将 `req.Response` 追加到 `history` 变量中。

## 4.5 超时设置
`Request`发出后，如果服务端迟迟没有响应，那岂不是很尴尬。那么我们就会想，
能否为请求设置超时规则呢？毫无疑问，当然可以。

超时可以分为**连接超时**和**响应读取超时**，这些都可以设置。
但正常情况下，并不想有那么明确的区别，那么也可以设置个总超时。

### 4.5.1 总超时
总的超时时间的设置是绑定在 `Client` 的一个名为 `Timeout` 的成员之上，
`Timeout` 是 `time.Duration`类型。

假设这是超时时间为 10 秒，示例代码：
```
client := http.Client{
	Timeout:   time.Duration(10 * time.Second),
}
```
### 4.5.2 连接超时
连接超时可通过 `Client` 中的 `Transport` 实现。
`Transport` 中有个名为 `Dial` 的成员函数，可用设置连接超时。
**`Transport` 是 `HTTP` 底层的数据运输者**。

假设设置连接超时时间为 2 秒
```
t := &http.Transport{
	Dial: func(network, addr string) (net.Conn, error) {
		timeout := time.Duration(2 * time.Second)
		return net.DialTimeout(network, addr, timeout)
	},
}
```
在 `Dial` 的函数中，我们通过 `net.DialTimeout` 进行网络连接，实现了连接超时功能。

### 4.5.3 读取超时
读取超时也要通过 `Client` 的 `Transport` 设置，比如设置响应的读取为 `8` 秒
```
t := &http.Transport{
	ResponseHeaderTimeout: time.Second * 8,
}
```

### 4.5.4 综合示例
```
t := &http.Transport{
    // 连接超时设置
	Dial: func(network, addr string) (net.Conn, error) {
		timeout := time.Duration(2 * time.Second)
		return net.DialTimeout(network, addr, timeout)
	},
	// 读取超时设置
	ResponseHeaderTimeout: time.Second * 8,
}
client := http.Client{
	Transport: t,
	// 总超时
	Timeout:   time.Duration(10 * time.Second),
}
```

### 4.5.5 其余超时设置
除了上面的几个超时设置，`Transport`还有其他一些关于超时的设置，
可以看下 `Transport` 的定义，还有发现三个与超时相关的定义：
```
// IdleConnTimeout is the maximum amount of time an idle
// (keep-alive) connection will remain idle before closing
// itself.
// Zero means no limit.
IdleConnTimeout time.Duration
 
// ResponseHeaderTimeout, if non-zero, specifies the amount of
// time to wait for a server's response headers after fully
// writing the request (including its body, if any). This
// time does not include the time to read the response body.
ResponseHeaderTimeout time.Duration
 
// ExpectContinueTimeout, if non-zero, specifies the amount of
// time to wait for a server's first response headers after fully
// writing the request headers if the request has an
// "Expect: 100-continue" header. Zero means no timeout and
// causes the body to be sent immediately, without
// waiting for the server to approve.
// This time does not include the time to send the request header.
ExpectContinueTimeout time.Duration
```
分别是 `IdleConnTimeout` （连接空闲超时时间，`keep-live` 开启）、
`TLSHandshakeTimeout` （`TLS` 握手时间）和 
`ExpectContinueTimeout`（似乎已含在 `ResponseHeaderTimeout` 中了，看注释）。


## 4.6 请求代理
代理还是挺重要的，特别对于开发爬虫的同学。那 `net/http` 怎么设置代理？
这个工作还是要依赖 `Client` 的成员 `Transport` 实现，
这个 `Transport` 还是挺重要的。

`Transport` 有个名为 `Proxy` 的成员，具体看看怎么使用吧。
假设我们要通过设置代理来请求谷歌的主页，代理地址为 `http://127.0.0.1:8087`。

```
proxyUrl, err := url.Parse("http://127.0.0.1:8087")
if err != nil {
	panic(err)
}
t := &http.Transport{
	Proxy:           http.ProxyURL(proxyUrl),
	TLSClientConfig: &tls.Config{InsecureSkipVerify: true},
}
client := http.Client{
	Transport: t,
	Timeout:   time.Duration(10 * time.Second),
}
 
r, err := client.Get("https://google.com")
```
主要关注 `http.Transport` 创建的代码。两个参数，`Proxy` 和 `TLSClientConfig`
分别用于设置代理和禁用 `https` 验证。我发现其实不设置 `TLSClientConfig` 
也可以请求成功，具体原因没仔细研究。

# 补充
`GO` 其实也提供了对应于 `requests` 的克隆版本，github地址为: https://github.com/levigross/grequests
